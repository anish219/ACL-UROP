import gymimport numpy as npimport matplotlib.pyplot as pltfrom reinforce_policy import Policynumber_of_episodes = 1step_size_initial = 1step_size_decay = 0.8data = []env = gym.make('CartPole-v0')my_policy = Policy()step_size = step_size_initialfor episode in range(number_of_episodes):    state_old = env.reset()     done = False    episode_database = []    time_step = 0        while not done:        # env.render()        time_step += 1        action = my_policy.choose_action(state_old)        state_new, reward, done, _ = env.step(action)        episode_database.append((state_old, action))        state_old = state_new    data.append(time_step)    if time_step <= 200:        #If not surviving over 200 timesteps, update parameters        for i, pair in enumerate(episode_database):            estimated_return = time_step - i - 1            my_policy.update(pair[0], pair[1], estimated_return, step_size)        step_size *= step_size_decay        print('dub: ', my_policy.W)    # print('Episode ' + str(episode) + ' ended in ' + str(time_step) + ' time steps')    # print('Current step size: ' + str(step_size))env.close()# plt.plot(data)# plt.title('Episode Duration', fontsize=16)# plt.xlabel('Episode #')# plt.ylabel('# of Timesteps')# x = np.array([i for i in range(len(data))])# m, b = np.polyfit(x, data, 1)# plt.plot(x, m*x+b)# plt.show()